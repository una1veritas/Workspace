%利得比基準について
\subsection{情報利得比基準}
先に述べた利得基準は非常に結果が得られるが，
多数の値をとる質問を偏重する欠陥を持っている．
例えば，質問として選んだ属性が氏名などの場合，
1事例からなるたくさんの部分集合が得られることとなり，
$info_{X}(T)=0$となる．したがって，この属性を用いて
事例の集合を分割すれば，情報量の利得は最大になる．
しかしながら，このような分割は全くの無益である．\\
　利得基準に伴うこのような偏重は，一種の正規化によって
矯正することができる．すなわち，多数の値を取ることによって
得られた利得部分を調整すればよい．ある事例に関して，
それがどのクラスに属するかではなく，その質問結果自体を伝える
メッセージの情報量を考える．info(S)の定義からの類推により，
分割情報量を\\
\begin{displaymath}
split\;info_{X}(T)=-\sum^k_{j=1}\frac{|T_{i}|}{|T|}\times\log_2\left(\frac{|T_{i}|}{|T|}\right) ビット
\end{displaymath}\\
と定める．これは{\it T}を{\it n}個の部分集合へ分割することによって得られる
全情報量を表す．一方，情報量利得は，そのうちのクラス分けにかかわる
部分の情報量を表す．したがって，利得比\\
\begin{displaymath}
gain\;ratio(X)=gain(X)/split\;info(X)
\end{displaymath}\\
は，分割によって得られる情報量のうち，有益な部分，すなわち，
クラス分類に役立つ部分の割合を表す．ところで，分割が自明な分割に近いときは，
分割情報量の値が小さいために利得比の値が不安定になる．
そこで，利得比基準では，全質問中で情報量利得が少なくとも平均以上で
あるという制約下でこの利得比を最大にする質問を選ぶ．\\
　この評価基準の下では，先ほど述べた欠陥部分は高く評価されない．
クラスの数を{\it k}とすると上式の分子(情報量利得)は高々$\log_2(k)$となる．
一方，事例数を{\it n}とすれば，質問結果も{\it n}通りに分割されるので，
分母は$\log_2(n)$となる．ここで事例数{\it n}は，クラス数{\it k}よりずっと
大きいので，利得比は小さな値となる．
